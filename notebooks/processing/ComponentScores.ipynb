{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicted Component Scores from Composite\n",
    "\n",
    "We're only given composite scores along with component ranks of each school, let's try to approximate the component scores given the composite formula:\n",
    "```\n",
    "composite = (0.5 * equity) + (0.25 * excellence) + (0.25 * efficiency)\n",
    "```\n",
    "\n",
    "## Linear Model\n",
    "If we assume a linear relationship between ranks (0 is the worst) and component scores we have the additional relationships:\n",
    "```\n",
    "rank_normalized =  rank / total_schools\n",
    "\n",
    "equity = equity_scaling_factor * equity_rank_normalized\n",
    "excellence = excellence_scaling_factor * excellence_rank_normalized\n",
    "efficiency = efficiency_scaling_factor * efficiency_rank_normalized\n",
    "```\n",
    "\n",
    "Combinging these we arrive at the equation we're trying to solve for:\n",
    "```\n",
    "composite = (0.5 * equity_scaling_factor * equity_rank_normalized) \n",
    "    + (0.25 * excellence_scaling_factor * excellence_rank_normalized) \n",
    "    + (0.25 * efficiency_scaling_factor * efficiency_rank_normalized)\n",
    "\n",
    "composite = beta_0 \n",
    "    + (beta_1 * equity_rank_normalized) \n",
    "    + (beta_2 * excellence_rank_normalized) \n",
    "    + (beta_3 * efficiency_rank_normalized)\n",
    "```\n",
    "\n",
    "Solving for the `betas` allows us to then approcimate the individual component scores.\n",
    "\n",
    "## Power Model\n",
    "Although we don't know the shape of the distribution of each component score, we do we see that the composite score distribution is only mostly linear. The top and bottom end have increased slopes which is better fitted with a power model, if we assume the composite score distrubution is also representative of the component score distributions we can instead fit a power model solving for `p`s:\n",
    "```\n",
    "composite = (0.5 * equity_rank_normalized ** p_equity) \n",
    "    + (0.25 * excellence_rank_normalized ** p_excellence) \n",
    "    + (0.25 * efficiency_rank_normalized ** p_efficiency)\n",
    "```\n",
    "\n",
    "## Results\n",
    "Errors were slightly lower with the power model.\n",
    "\n",
    "Linear Model Errors:\n",
    "- mae: 5.17455588230908\n",
    "- mse: 54.18475698406821\n",
    "- rmse: 7.3610296143996194\n",
    "\n",
    "Power Model Errors\n",
    "- mae: 4.710755158241806\n",
    "- mse: 45.38759555751562\n",
    "- rmse: 6.737031657749251"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run notebooks/Setup.ipynb\n",
    "\n",
    "import polars\n",
    "import numpy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate Component Scores from Composite\n",
    "\n",
    "We're only given composite scores along with component ranks of each school, let's try to approximate the component scores given the composite formula:\n",
    "```\n",
    "composite = (0.5 * equity) + (0.25 * excellence) + (0.25 * efficiency)\n",
    "```\n",
    "\n",
    "## Linear Model\n",
    "If we assume a linear relationship between ranks (0 is the worst) and component scores we have the additional relationships:\n",
    "```\n",
    "rank_normalized =  rank / total_schools\n",
    "\n",
    "equity = equity_scaling_factor * equity_rank_normalized\n",
    "excellence = excellence_scaling_factor * excellence_rank_normalized\n",
    "efficiency = efficiency_scaling_factor * efficiency_rank_normalized\n",
    "```\n",
    "\n",
    "Combinging these we arrive at the equation we're trying to solve for:\n",
    "```\n",
    "composite = (0.5 * equity_scaling_factor * equity_rank_normalized) \n",
    "    + (0.25 * excellence_scaling_factor * excellence_rank_normalized) \n",
    "    + (0.25 * efficiency_scaling_factor * efficiency_rank_normalized)\n",
    "\n",
    "composite = beta_0 \n",
    "    + (beta_1 * equity_rank_normalized) \n",
    "    + (beta_2 * excellence_rank_normalized) \n",
    "    + (beta_3 * efficiency_rank_normalized)\n",
    "```\n",
    "\n",
    "Solving for the `betas` allows us to then approcimate the individual component scores.\n",
    "\n",
    "## Power Model\n",
    "Although we don't know the shape of the distribution of each component score, we do we see that the composite score distribution is only mostly linear. The top and bottom end have increased slopes which is better fitted with a power model, if we assume the composite score distrubution is also representative of the component score distributions we can instead fit a power model solving for `p`s:\n",
    "```\n",
    "composite = (0.5 * equity_rank_normalized ** p_equity) \n",
    "    + (0.25 * excellence_rank_normalized ** p_excellence) \n",
    "    + (0.25 * efficiency_rank_normalized ** p_efficiency)\n",
    "```\n",
    "\n",
    "## Results\n",
    "Errors were slightly lower with the power model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (101, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>school_name</th><th>composite_score</th><th>equity_rank</th><th>excellence_rank</th><th>efficiency_rank</th><th>equity_rank_normalized</th><th>excellence_rank_normalized</th><th>efficiency_rank_normalized</th><th>composite_normalized</th></tr><tr><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Washington (George) High&quot;</td><td>72.91</td><td>81</td><td>52</td><td>98</td><td>0.81</td><td>0.52</td><td>0.98</td><td>0.7291</td></tr><tr><td>&quot;Presidio Middle&quot;</td><td>51.16</td><td>52</td><td>44</td><td>94</td><td>0.52</td><td>0.44</td><td>0.94</td><td>0.5116</td></tr><tr><td>&quot;Lafayette Elementary&quot;</td><td>23.61</td><td>7</td><td>96</td><td>48</td><td>0.07</td><td>0.96</td><td>0.48</td><td>0.2361</td></tr><tr><td>&quot;Alamo Elementary&quot;</td><td>14.13</td><td>6</td><td>74</td><td>35</td><td>0.06</td><td>0.74</td><td>0.35</td><td>0.1413</td></tr><tr><td>&quot;Argonne Elementary&quot;</td><td>11.46</td><td>4</td><td>75</td><td>40</td><td>0.04</td><td>0.75</td><td>0.4</td><td>0.1146</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Milk (Harvey) Civil Rights Ele…</td><td>21.5</td><td>9</td><td>73</td><td>71</td><td>0.09</td><td>0.73</td><td>0.71</td><td>0.215</td></tr><tr><td>&quot;Everett Middle&quot;</td><td>15.2</td><td>79</td><td>1</td><td>4</td><td>0.79</td><td>0.01</td><td>0.04</td><td>0.152</td></tr><tr><td>&quot;Lilienthal (Claire) Elementary&quot;</td><td>40.88</td><td>31</td><td>87</td><td>61</td><td>0.31</td><td>0.87</td><td>0.61</td><td>0.4088</td></tr><tr><td>&quot;Marina Middle&quot;</td><td>35.98</td><td>65</td><td>17</td><td>49</td><td>0.65</td><td>0.17</td><td>0.49</td><td>0.3598</td></tr><tr><td>&quot;Sherman Elementary&quot;</td><td>13.85</td><td>15</td><td>64</td><td>14</td><td>0.15</td><td>0.64</td><td>0.14</td><td>0.1385</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (101, 9)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ school_na ┆ composite ┆ equity_ra ┆ excellenc ┆ … ┆ equity_ra ┆ excellenc ┆ efficienc ┆ composit │\n",
       "│ me        ┆ _score    ┆ nk        ┆ e_rank    ┆   ┆ nk_normal ┆ e_rank_no ┆ y_rank_no ┆ e_normal │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ized      ┆ rmalized  ┆ rmalized  ┆ ized     │\n",
       "│ str       ┆ f64       ┆ i64       ┆ i64       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ Washingto ┆ 72.91     ┆ 81        ┆ 52        ┆ … ┆ 0.81      ┆ 0.52      ┆ 0.98      ┆ 0.7291   │\n",
       "│ n         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ (George)  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ High      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Presidio  ┆ 51.16     ┆ 52        ┆ 44        ┆ … ┆ 0.52      ┆ 0.44      ┆ 0.94      ┆ 0.5116   │\n",
       "│ Middle    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Lafayette ┆ 23.61     ┆ 7         ┆ 96        ┆ … ┆ 0.07      ┆ 0.96      ┆ 0.48      ┆ 0.2361   │\n",
       "│ Elementar ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ y         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Alamo Ele ┆ 14.13     ┆ 6         ┆ 74        ┆ … ┆ 0.06      ┆ 0.74      ┆ 0.35      ┆ 0.1413   │\n",
       "│ mentary   ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Argonne   ┆ 11.46     ┆ 4         ┆ 75        ┆ … ┆ 0.04      ┆ 0.75      ┆ 0.4       ┆ 0.1146   │\n",
       "│ Elementar ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ y         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ Milk      ┆ 21.5      ┆ 9         ┆ 73        ┆ … ┆ 0.09      ┆ 0.73      ┆ 0.71      ┆ 0.215    │\n",
       "│ (Harvey)  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Civil     ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Rights    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Ele…      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Everett   ┆ 15.2      ┆ 79        ┆ 1         ┆ … ┆ 0.79      ┆ 0.01      ┆ 0.04      ┆ 0.152    │\n",
       "│ Middle    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Lilientha ┆ 40.88     ┆ 31        ┆ 87        ┆ … ┆ 0.31      ┆ 0.87      ┆ 0.61      ┆ 0.4088   │\n",
       "│ l         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ (Claire)  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Elementar ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ y         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Marina    ┆ 35.98     ┆ 65        ┆ 17        ┆ … ┆ 0.65      ┆ 0.17      ┆ 0.49      ┆ 0.3598   │\n",
       "│ Middle    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Sherman   ┆ 13.85     ┆ 15        ┆ 64        ┆ … ┆ 0.15      ┆ 0.64      ┆ 0.14      ┆ 0.1385   │\n",
       "│ Elementar ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ y         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# source data we're going to be working with\n",
    "composite_df = polars.read_csv(workspace_path.joinpath('data/processed/composite_scores_raw.csv'))\n",
    "composite_df\n",
    "\n",
    "# normalize the ranks, the max is the same across components\n",
    "max_rank = composite_df['equity_rank'].max()\n",
    "\n",
    "normalized_df = composite_df\\\n",
    "    .select(['school_name', 'composite_score', 'equity_rank', 'excellence_rank', 'efficiency_rank'])\\\n",
    "    .with_columns([\n",
    "        (composite_df['equity_rank'] / max_rank).alias('equity_rank_normalized'),\n",
    "        (composite_df['excellence_rank'] / max_rank).alias('excellence_rank_normalized'),\n",
    "        (composite_df['efficiency_rank'] / max_rank).alias('efficiency_rank_normalized'),\n",
    "        (composite_df['composite_score'] / 100).alias('composite_normalized'),\n",
    "    ])\n",
    "\n",
    "normalized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrun the errors of the predictions to evaluate the model\n",
    "def errors(predicted_df):\n",
    "    mae = mean_absolute_error(predicted_df['composite_score'], predicted_df['composite_score_predicted'])\n",
    "    mse = mean_squared_error(predicted_df['composite_score'], predicted_df['composite_score_predicted'])\n",
    "    \n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'mse': mse,\n",
    "        'rmse': numpy.sqrt(mse)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " np.float64(0.3964423881149744),\n",
       " np.float64(0.15692051444902033),\n",
       " np.float64(0.2131077408232291))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup the regressions\n",
    "x = normalized_df.select(['equity_rank_normalized', 'excellence_rank_normalized', 'efficiency_rank_normalized'])\\\n",
    "    .to_numpy()\n",
    "y = normalized_df['composite_normalized'].to_numpy()\n",
    "\n",
    "# fit\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(x, y)\n",
    "beta_0 = model.intercept_\n",
    "beta_1, beta_2, beta_3 = model.coef_\n",
    "\n",
    "beta_0, beta_1, beta_2, beta_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': np.float64(5.17455588230908),\n",
       " 'mse': np.float64(54.18475698406821),\n",
       " 'rmse': np.float64(7.3610296143996194)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict and eval\n",
    "equity_scaling_factor = beta_1 / 0.5\n",
    "excellence_scaling_factor = beta_2 / 0.25\n",
    "efficiency_scaling_factor = beta_3 / 0.25\n",
    "\n",
    "linear_predictions = normalized_df.with_columns([\n",
    "    (equity_scaling_factor * normalized_df['equity_rank_normalized'] * 100).alias('equity_score_predicted'),\n",
    "    (excellence_scaling_factor * normalized_df['excellence_rank_normalized'] * 100).alias('excellence_score_predicted'),\n",
    "    (efficiency_scaling_factor * normalized_df['efficiency_rank_normalized'] * 100).alias('efficiency_score_predicted'),\n",
    "])\n",
    "\n",
    "linear_predictions = linear_predictions.with_columns(\n",
    "    (\n",
    "        0.5 * linear_predictions['equity_score_predicted'] +\n",
    "        0.25 * linear_predictions['excellence_score_predicted'] +\n",
    "        0.25 * linear_predictions['efficiency_score_predicted'] -\n",
    "        beta_0\n",
    "    ).alias('composite_score_predicted')\n",
    ")\n",
    "\n",
    "errors(linear_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(params, data):\n",
    "    p_equity, p_excellence, p_efficiency = params\n",
    "    \n",
    "    # estimate the parts and composite\n",
    "    data['s_equity'] = data['equity_rank_normalized'] ** p_equity\n",
    "    data['s_excellence'] = data['excellence_rank_normalized'] ** p_excellence\n",
    "    data['s_efficiency'] = data['efficiency_rank_normalized'] ** p_efficiency\n",
    "    \n",
    "    data['composite_estimated'] = (\n",
    "        0.5 * data['s_equity'] +\n",
    "        0.25 * data['s_excellence'] +\n",
    "        0.25 * data['s_efficiency']\n",
    "    )\n",
    "    \n",
    "    # return sum squared of errors to minimize\n",
    "    sse = numpy.sum((data['composite_normalized'] - data['composite_estimated']) ** 2)\n",
    "    \n",
    "    return sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 0.45841471513090776\n",
       "        x: [ 1.212e+00  1.489e+00  3.536e+00]\n",
       "      nit: 15\n",
       "      jac: [-8.882e-08  3.830e-07  5.551e-09]\n",
       "     nfev: 72\n",
       "     njev: 18\n",
       " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_params = [1.0, 1.0, 1.0]\n",
    "bounds = [(0.1, 10), (0.1, 10), (0.1, 10)]\n",
    "\n",
    "result = minimize(\n",
    "    fit,\n",
    "    initial_params,\n",
    "    args=(normalized_df.to_pandas(),),\n",
    "    bounds=bounds,\n",
    "    method='L-BFGS-B'\n",
    ")\n",
    "\n",
    "# extract the powers\n",
    "p_equity, p_excellence, p_efficiency = result.x\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': np.float64(4.710755158241806),\n",
       " 'mse': np.float64(45.38759555751562),\n",
       " 'rmse': np.float64(6.737031657749251)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict and eval\n",
    "power_predictions = normalized_df.with_columns([\n",
    "    (normalized_df['equity_rank_normalized'] ** p_equity * 100).alias('equity_score_predicted'),\n",
    "    (normalized_df['excellence_rank_normalized'] ** p_excellence * 100).alias('excellence_score_predicted'),\n",
    "    (normalized_df['efficiency_rank_normalized'] ** p_efficiency * 100).alias('efficiency_score_predicted'),\n",
    "])\n",
    "\n",
    "power_predictions = power_predictions.with_columns(\n",
    "    (\n",
    "        0.5 * power_predictions['equity_score_predicted'] +\n",
    "        0.25 * power_predictions['excellence_score_predicted'] +\n",
    "        0.25 * power_predictions['efficiency_score_predicted']\n",
    "    ).alias('composite_score_predicted')\n",
    ")\n",
    "\n",
    "errors(power_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Approximates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_predictions_renamed = linear_predictions\\\n",
    "    .select(['school_name', 'equity_score_predicted', 'excellence_score_predicted', 'efficiency_score_predicted', 'composite_score_predicted'])\\\n",
    "    .rename({\n",
    "        'equity_score_predicted': 'equity_score_lmodel',\n",
    "        'excellence_score_predicted': 'excellence_score_lmodel',\n",
    "        'efficiency_score_predicted': 'efficiency_score_lmodel',\n",
    "        'composite_score_predicted': 'composite_score_lmodel'\n",
    "    })\n",
    "\n",
    "power_predictions_renamed = power_predictions\\\n",
    "    .select(['school_name', 'equity_score_predicted', 'excellence_score_predicted', 'efficiency_score_predicted', 'composite_score_predicted'])\\\n",
    "    .rename({\n",
    "        'equity_score_predicted': 'equity_score_pmodel',\n",
    "        'excellence_score_predicted': 'excellence_score_pmodel',\n",
    "        'efficiency_score_predicted': 'efficiency_score_pmodel',\n",
    "        'composite_score_predicted': 'composite_score_pmodel'\n",
    "    })\n",
    "\n",
    "# merge with original\n",
    "combined_predictions = composite_df\\\n",
    "    .select(['school_name', 'composite_score', 'equity_rank', 'excellence_rank', 'efficiency_rank'])\\\n",
    "    .join(\n",
    "        linear_predictions_renamed, \n",
    "        on='school_name', \n",
    "        how='left'\n",
    "    )\\\n",
    "    .join(\n",
    "        power_predictions_renamed, \n",
    "        on='school_name', \n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "combined_predictions.write_csv(workspace_path.joinpath('data/processed/component_scores.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
