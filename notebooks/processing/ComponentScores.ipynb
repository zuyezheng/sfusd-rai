{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicted Component Scores from Composite\n",
    "\n",
    "We're only given composite scores along with component ranks of each school, let's try to approximate the component scores given the composite formula:\n",
    "```\n",
    "composite = (0.5 * equity) + (0.25 * excellence) + (0.25 * efficiency)\n",
    "```\n",
    "\n",
    "## Linear Model\n",
    "If we assume a linear relationship between ranks (0 is the worst) and component scores we have the additional relationships:\n",
    "```\n",
    "rank_normalized =  rank / total_schools\n",
    "\n",
    "equity = equity_scaling_factor * equity_rank_normalized\n",
    "excellence = excellence_scaling_factor * excellence_rank_normalized\n",
    "efficiency = efficiency_scaling_factor * efficiency_rank_normalized\n",
    "```\n",
    "\n",
    "Combinging these we arrive at the equation we're trying to solve for:\n",
    "```\n",
    "composite = (0.5 * equity_scaling_factor * equity_rank_normalized) \n",
    "    + (0.25 * excellence_scaling_factor * excellence_rank_normalized) \n",
    "    + (0.25 * efficiency_scaling_factor * efficiency_rank_normalized)\n",
    "\n",
    "composite = beta_0 \n",
    "    + (beta_1 * equity_rank_normalized) \n",
    "    + (beta_2 * excellence_rank_normalized) \n",
    "    + (beta_3 * efficiency_rank_normalized)\n",
    "```\n",
    "\n",
    "Solving for the `betas` allows us to then approcimate the individual component scores.\n",
    "\n",
    "## Power Model\n",
    "Although we don't know the shape of the distribution of each component score, we do we see that the composite score distribution is only mostly linear. The head and tail have increased slopes which is better fitted with a power model, if we assume the composite score distrubution is also representative of the component score distributions we can instead fit a power model solving for `p`s:\n",
    "```\n",
    "composite = (0.5 * equity_rank_normalized ** p_equity) \n",
    "    + (0.25 * excellence_rank_normalized ** p_excellence) \n",
    "    + (0.25 * efficiency_rank_normalized ** p_efficiency)\n",
    "```\n",
    "\n",
    "## Skewed Normal Model\n",
    "Looking at the results, the head and tail of each ranks have much higher errors (even with a power model). This is likely due to the fact that the rank is linear, but the actual is likely a skewed normal distribution.\n",
    "\n",
    "Consider \"excellence\" which is a measure of academics, most schools likely perform similarly clustered in the \"middle\" with less less lower and higher performing schools forming a bell curve or skewed bell curve. This is likely for all component scores so lets use this assumption to fit a model as well.\n",
    "\n",
    "Like the rest, lets use a regression to fit a normal distribution for each component score.\n",
    "\n",
    "## Results\n",
    "Skewed normal does slightly better especially for MSE.\n",
    "\n",
    "Linear Model Errors:\n",
    "- MAE: 5.1746\n",
    "- MSE: 54.1848\n",
    "- RMSE: 7.3610\n",
    "\n",
    "Power Model Errors\n",
    "- MAE: 4.7108\n",
    "- MSE: 45.3876\n",
    "- RMSE: 6.7370\n",
    "\n",
    "Skewed Normal Model Errors\n",
    "- MAE: 4.1992\n",
    "- MSE: 37.5471\n",
    "- RMSE: 6.1276\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run notebooks/Setup.ipynb\n",
    "\n",
    "import polars\n",
    "import numpy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import skewnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (101, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>school_name</th><th>composite_score</th><th>equity_rank</th><th>excellence_rank</th><th>efficiency_rank</th><th>equity_rank_normalized</th><th>excellence_rank_normalized</th><th>efficiency_rank_normalized</th><th>composite_normalized</th></tr><tr><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Washington (George) High&quot;</td><td>72.91</td><td>81</td><td>52</td><td>98</td><td>0.803922</td><td>0.519608</td><td>0.970588</td><td>0.7291</td></tr><tr><td>&quot;Presidio Middle&quot;</td><td>51.16</td><td>52</td><td>44</td><td>94</td><td>0.519608</td><td>0.441176</td><td>0.931373</td><td>0.5116</td></tr><tr><td>&quot;Lafayette Elementary&quot;</td><td>23.61</td><td>7</td><td>96</td><td>48</td><td>0.078431</td><td>0.95098</td><td>0.480392</td><td>0.2361</td></tr><tr><td>&quot;Alamo Elementary&quot;</td><td>14.13</td><td>6</td><td>74</td><td>35</td><td>0.068627</td><td>0.735294</td><td>0.352941</td><td>0.1413</td></tr><tr><td>&quot;Argonne Elementary&quot;</td><td>11.46</td><td>4</td><td>75</td><td>40</td><td>0.04902</td><td>0.745098</td><td>0.401961</td><td>0.1146</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Milk (Harvey) Civil Rights Ele…</td><td>21.5</td><td>9</td><td>73</td><td>71</td><td>0.098039</td><td>0.72549</td><td>0.705882</td><td>0.215</td></tr><tr><td>&quot;Everett Middle&quot;</td><td>15.2</td><td>79</td><td>1</td><td>4</td><td>0.784314</td><td>0.019608</td><td>0.04902</td><td>0.152</td></tr><tr><td>&quot;Lilienthal (Claire) Elementary&quot;</td><td>40.88</td><td>31</td><td>87</td><td>61</td><td>0.313725</td><td>0.862745</td><td>0.607843</td><td>0.4088</td></tr><tr><td>&quot;Marina Middle&quot;</td><td>35.98</td><td>65</td><td>17</td><td>49</td><td>0.647059</td><td>0.176471</td><td>0.490196</td><td>0.3598</td></tr><tr><td>&quot;Sherman Elementary&quot;</td><td>13.85</td><td>15</td><td>64</td><td>14</td><td>0.156863</td><td>0.637255</td><td>0.147059</td><td>0.1385</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (101, 9)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ school_na ┆ composite ┆ equity_ra ┆ excellenc ┆ … ┆ equity_ra ┆ excellenc ┆ efficienc ┆ composit │\n",
       "│ me        ┆ _score    ┆ nk        ┆ e_rank    ┆   ┆ nk_normal ┆ e_rank_no ┆ y_rank_no ┆ e_normal │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ized      ┆ rmalized  ┆ rmalized  ┆ ized     │\n",
       "│ str       ┆ f64       ┆ i64       ┆ i64       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ Washingto ┆ 72.91     ┆ 81        ┆ 52        ┆ … ┆ 0.803922  ┆ 0.519608  ┆ 0.970588  ┆ 0.7291   │\n",
       "│ n         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ (George)  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ High      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Presidio  ┆ 51.16     ┆ 52        ┆ 44        ┆ … ┆ 0.519608  ┆ 0.441176  ┆ 0.931373  ┆ 0.5116   │\n",
       "│ Middle    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Lafayette ┆ 23.61     ┆ 7         ┆ 96        ┆ … ┆ 0.078431  ┆ 0.95098   ┆ 0.480392  ┆ 0.2361   │\n",
       "│ Elementar ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ y         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Alamo Ele ┆ 14.13     ┆ 6         ┆ 74        ┆ … ┆ 0.068627  ┆ 0.735294  ┆ 0.352941  ┆ 0.1413   │\n",
       "│ mentary   ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Argonne   ┆ 11.46     ┆ 4         ┆ 75        ┆ … ┆ 0.04902   ┆ 0.745098  ┆ 0.401961  ┆ 0.1146   │\n",
       "│ Elementar ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ y         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ Milk      ┆ 21.5      ┆ 9         ┆ 73        ┆ … ┆ 0.098039  ┆ 0.72549   ┆ 0.705882  ┆ 0.215    │\n",
       "│ (Harvey)  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Civil     ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Rights    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Ele…      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Everett   ┆ 15.2      ┆ 79        ┆ 1         ┆ … ┆ 0.784314  ┆ 0.019608  ┆ 0.04902   ┆ 0.152    │\n",
       "│ Middle    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Lilientha ┆ 40.88     ┆ 31        ┆ 87        ┆ … ┆ 0.313725  ┆ 0.862745  ┆ 0.607843  ┆ 0.4088   │\n",
       "│ l         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ (Claire)  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Elementar ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ y         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Marina    ┆ 35.98     ┆ 65        ┆ 17        ┆ … ┆ 0.647059  ┆ 0.176471  ┆ 0.490196  ┆ 0.3598   │\n",
       "│ Middle    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Sherman   ┆ 13.85     ┆ 15        ┆ 64        ┆ … ┆ 0.156863  ┆ 0.637255  ┆ 0.147059  ┆ 0.1385   │\n",
       "│ Elementar ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ y         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# source data we're going to be working with\n",
    "composite_df = polars.read_csv(workspace_path.joinpath('data/processed/composite_scores_raw.csv'))\n",
    "composite_df\n",
    "\n",
    "# normalize the ranks, the max is the same across components\n",
    "max_rank = composite_df['equity_rank'].max() + 2\n",
    "\n",
    "normalized_df = composite_df\\\n",
    "    .select(['school_name', 'composite_score', 'equity_rank', 'excellence_rank', 'efficiency_rank'])\\\n",
    "    .with_columns([\n",
    "        ((composite_df['equity_rank'] + 1) / max_rank).alias('equity_rank_normalized'),\n",
    "        ((composite_df['excellence_rank'] + 1) / max_rank).alias('excellence_rank_normalized'),\n",
    "        ((composite_df['efficiency_rank'] + 1) / max_rank).alias('efficiency_rank_normalized'),\n",
    "        (composite_df['composite_score'] / 100).alias('composite_normalized'),\n",
    "    ])\n",
    "\n",
    "normalized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrun the errors of the predictions to evaluate the model\n",
    "def errors(predicted_df):\n",
    "    mae = mean_absolute_error(predicted_df['composite_score'], predicted_df['composite_score_predicted'])\n",
    "    mse = mean_squared_error(predicted_df['composite_score'], predicted_df['composite_score_predicted'])\n",
    "    \n",
    "    print(f'MAE: {mae:.4f}')\n",
    "    print(f'MSE: {mse:.4f}')\n",
    "    print(f'RMSE: {numpy.sqrt(mse):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " np.float64(0.3976023674406394),\n",
       " np.float64(0.15368622846912555),\n",
       " np.float64(0.21555430851378687))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup the regressions\n",
    "x = normalized_df.select(['equity_rank_normalized', 'excellence_rank_normalized', 'efficiency_rank_normalized'])\\\n",
    "    .to_numpy()\n",
    "y = normalized_df['composite_normalized'].to_numpy()\n",
    "\n",
    "# fit\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(x, y)\n",
    "beta_0 = model.intercept_\n",
    "beta_1, beta_2, beta_3 = model.coef_\n",
    "\n",
    "beta_0, beta_1, beta_2, beta_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 5.3005\n",
      "MSE: 56.2090\n",
      "RMSE: 7.4973\n"
     ]
    }
   ],
   "source": [
    "# predict and eval\n",
    "equity_scaling_factor = beta_1 / 0.5\n",
    "excellence_scaling_factor = beta_2 / 0.25\n",
    "efficiency_scaling_factor = beta_3 / 0.25\n",
    "\n",
    "linear_predictions = normalized_df.with_columns([\n",
    "    (equity_scaling_factor * normalized_df['equity_rank_normalized'] * 100).alias('equity_score_predicted'),\n",
    "    (excellence_scaling_factor * normalized_df['excellence_rank_normalized'] * 100).alias('excellence_score_predicted'),\n",
    "    (efficiency_scaling_factor * normalized_df['efficiency_rank_normalized'] * 100).alias('efficiency_score_predicted'),\n",
    "])\n",
    "\n",
    "linear_predictions = linear_predictions.with_columns(\n",
    "    (\n",
    "        0.5 * linear_predictions['equity_score_predicted'] +\n",
    "        0.25 * linear_predictions['excellence_score_predicted'] +\n",
    "        0.25 * linear_predictions['efficiency_score_predicted'] -\n",
    "        beta_0\n",
    "    ).alias('composite_score_predicted')\n",
    ")\n",
    "\n",
    "errors(linear_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(params, data):\n",
    "    b_equity, b_excellence, b_efficiency, p_equity, p_excellence, p_efficiency = params\n",
    "    \n",
    "    # estimate the parts and composite\n",
    "    data['s_equity'] = b_equity * data['equity_rank_normalized'] ** p_equity\n",
    "    data['s_excellence'] = b_excellence * data['excellence_rank_normalized'] ** p_excellence\n",
    "    data['s_efficiency'] = b_efficiency * data['efficiency_rank_normalized'] ** p_efficiency\n",
    "    \n",
    "    data['composite_estimated'] = (\n",
    "        0.5 * data['s_equity'] +\n",
    "        0.25 * data['s_excellence'] +\n",
    "        0.25 * data['s_efficiency']\n",
    "    )\n",
    "    \n",
    "    # return sum squared of errors to minimize\n",
    "    sse = numpy.sum((data['composite_normalized'] - data['composite_estimated']) ** 2)\n",
    "    \n",
    "    return sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 0.4231055467648279\n",
       "        x: [ 8.993e-01  9.060e-01  1.064e+00  1.141e+00  1.240e+00\n",
       "             2.956e+00]\n",
       "      nit: 23\n",
       "      jac: [ 3.686e-06  2.048e-06 -3.830e-07 -9.270e-07 -3.442e-07\n",
       "            -4.996e-08]\n",
       "     nfev: 175\n",
       "     njev: 25\n",
       " hess_inv: <6x6 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_params = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "bounds = [(-100, 100), (-100, 100), (-100, 100), (0.01, 20), (00.01, 20), (00.01, 20)]\n",
    "\n",
    "result = minimize(\n",
    "    fit,\n",
    "    initial_params,\n",
    "    args=(normalized_df.to_pandas(),),\n",
    "    bounds=bounds,\n",
    "    method='L-BFGS-B'\n",
    ")\n",
    "\n",
    "# extract the powers\n",
    "b_equity, b_excellence, b_efficiency, p_equity, p_excellence, p_efficiency = result.x\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 4.4308\n",
      "MSE: 41.8916\n",
      "RMSE: 6.4724\n"
     ]
    }
   ],
   "source": [
    "# predict and eval\n",
    "power_predictions = normalized_df.with_columns([\n",
    "    (b_equity * normalized_df['equity_rank_normalized'] ** p_equity * 100).alias('equity_score_predicted'),\n",
    "    (b_excellence * normalized_df['excellence_rank_normalized'] ** p_excellence * 100).alias('excellence_score_predicted'),\n",
    "    (b_efficiency * normalized_df['efficiency_rank_normalized'] ** p_efficiency * 100).alias('efficiency_score_predicted'),\n",
    "])\n",
    "\n",
    "power_predictions = power_predictions.with_columns(\n",
    "    (\n",
    "        0.5 * power_predictions['equity_score_predicted'] +\n",
    "        0.25 * power_predictions['excellence_score_predicted'] +\n",
    "        0.25 * power_predictions['efficiency_score_predicted']\n",
    "    ).alias('composite_score_predicted')\n",
    ")\n",
    "\n",
    "errors(power_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skewed Normal Distribution Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(params, data):\n",
    "    a_equity, a_excellence, a_efficiency, l_equity, l_excellence, l_efficiency, s_equity, s_excellence, s_efficiency = params\n",
    "    \n",
    "    # estimate the parts and composite\n",
    "    data['s_equity'] = skewnorm.ppf(data['equity_rank_normalized'], a_equity, loc=l_equity, scale=s_equity)\n",
    "    data['s_excellence'] = skewnorm.ppf(data['excellence_rank_normalized'], a_excellence, loc=l_excellence, scale=s_excellence)\n",
    "    data['s_efficiency'] = skewnorm.ppf(data['efficiency_rank_normalized'], a_efficiency, loc=l_efficiency, scale=s_efficiency)\n",
    "\n",
    "    data['composite_estimated'] = (\n",
    "        0.5 * data['s_equity'] +\n",
    "        0.25 * data['s_excellence'] +\n",
    "        0.25 * data['s_efficiency']\n",
    "    )\n",
    "    \n",
    "    # return sum squared of errors to minimize\n",
    "    sse = numpy.sum((data['composite_score'] - data['composite_estimated']) ** 2)\n",
    "    \n",
    "    return sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 1835.7595418624173\n",
       "        x: [-3.742e-07 -6.395e-07 -6.441e-07  3.762e+01  3.638e+01\n",
       "             3.638e+01  3.000e+01  3.000e+01  3.000e+01]\n",
       "      nit: 45\n",
       "      jac: [ 1.683e-03  9.095e-04  6.821e-04  1.819e-04  9.095e-05\n",
       "             4.547e-05 -1.190e+02 -3.644e+01 -6.072e+01]\n",
       "     nfev: 670\n",
       "     njev: 67\n",
       " hess_inv: <9x9 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_params = [0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0]\n",
    "bounds = [\n",
    "    (-20, 20), \n",
    "    (-20, 20),\n",
    "    (-20, 20),\n",
    "    (30, 70),\n",
    "    (30, 70),\n",
    "    (30, 70),\n",
    "    (1, 30),\n",
    "    (1, 30),\n",
    "    (1, 30)\n",
    "]\n",
    "\n",
    "result = minimize(\n",
    "    fit,\n",
    "    initial_params,\n",
    "    args=(normalized_df.to_pandas(),),\n",
    "    bounds=bounds,\n",
    "    method='L-BFGS-B'\n",
    ")\n",
    "\n",
    "a_equity, a_excellence, a_efficiency, l_equity, l_excellence, l_efficiency, s_equity, s_excellence, s_efficiency = result.x\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 4.1992\n",
      "MSE: 37.5471\n",
      "RMSE: 6.1276\n"
     ]
    }
   ],
   "source": [
    "# predict and eval\n",
    "normal_predictions = normalized_df.with_columns(\n",
    "    # need to clip between possible bounds\n",
    "    equity_score_predicted = numpy.clip(skewnorm.ppf(normalized_df['equity_rank_normalized'], a_equity, loc=l_equity, scale=s_equity), 0, 100),\n",
    "    excellence_score_predicted = numpy.clip(skewnorm.ppf(normalized_df['excellence_rank_normalized'], a_excellence, loc=l_excellence, scale=s_excellence), 0, 100),\n",
    "    efficiency_score_predicted = numpy.clip(skewnorm.ppf(normalized_df['efficiency_rank_normalized'], a_efficiency, loc=l_efficiency, scale=s_efficiency), 0, 100)\n",
    ")\n",
    "\n",
    "normal_predictions = normal_predictions.with_columns(\n",
    "    composite_score_predicted = (\n",
    "        0.5 * normal_predictions['equity_score_predicted'] +\n",
    "        0.25 * normal_predictions['excellence_score_predicted'] +\n",
    "        0.25 * normal_predictions['efficiency_score_predicted']\n",
    "    )\n",
    ")\n",
    "\n",
    "errors(normal_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save\n",
    "\n",
    "Combine with original file and save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (101, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>school_name</th><th>composite_score</th><th>equity_rank</th><th>excellence_rank</th><th>efficiency_rank</th><th>Enrollment</th><th>equity_score_p</th><th>excellence_score_p</th><th>efficiency_score_p</th><th>composite_score_p</th></tr><tr><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Washington (George) High&quot;</td><td>72.91</td><td>81</td><td>52</td><td>98</td><td>2091</td><td>63.294783</td><td>37.851138</td><td>93.061238</td><td>64.375485</td></tr><tr><td>&quot;Presidio Middle&quot;</td><td>51.16</td><td>52</td><td>44</td><td>94</td><td>996</td><td>39.098491</td><td>31.936443</td><td>80.958686</td><td>47.773028</td></tr><tr><td>&quot;Lafayette Elementary&quot;</td><td>23.61</td><td>7</td><td>96</td><td>48</td><td>468</td><td>0.0</td><td>86.009098</td><td>34.900858</td><td>30.227489</td></tr><tr><td>&quot;Alamo Elementary&quot;</td><td>14.13</td><td>6</td><td>74</td><td>35</td><td>390</td><td>0.0</td><td>55.243183</td><td>25.054181</td><td>20.074341</td></tr><tr><td>&quot;Argonne Elementary&quot;</td><td>11.46</td><td>4</td><td>75</td><td>40</td><td>389</td><td>0.0</td><td>56.150348</td><td>28.927687</td><td>21.269509</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Milk (Harvey) Civil Rights Ele…</td><td>21.5</td><td>9</td><td>73</td><td>71</td><td>133</td><td>0.0</td><td>54.352953</td><td>52.617792</td><td>26.742686</td></tr><tr><td>&quot;Everett Middle&quot;</td><td>15.2</td><td>79</td><td>1</td><td>4</td><td>404</td><td>61.228763</td><td>0.0</td><td>0.0</td><td>30.614381</td></tr><tr><td>&quot;Lilienthal (Claire) Elementary&quot;</td><td>40.88</td><td>31</td><td>87</td><td>61</td><td>674</td><td>23.063878</td><td>69.158131</td><td>44.586996</td><td>39.968221</td></tr><tr><td>&quot;Marina Middle&quot;</td><td>35.98</td><td>65</td><td>17</td><td>49</td><td>666</td><td>48.945168</td><td>8.509072</td><td>35.638621</td><td>35.509507</td></tr><tr><td>&quot;Sherman Elementary&quot;</td><td>13.85</td><td>15</td><td>64</td><td>14</td><td>293</td><td>7.400342</td><td>46.909982</td><td>4.901997</td><td>16.653166</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (101, 10)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ school_na ┆ composite ┆ equity_ra ┆ excellenc ┆ … ┆ equity_sc ┆ excellenc ┆ efficienc ┆ composit │\n",
       "│ me        ┆ _score    ┆ nk        ┆ e_rank    ┆   ┆ ore_p     ┆ e_score_p ┆ y_score_p ┆ e_score_ │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ p        │\n",
       "│ str       ┆ f64       ┆ i64       ┆ i64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ ---      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ Washingto ┆ 72.91     ┆ 81        ┆ 52        ┆ … ┆ 63.294783 ┆ 37.851138 ┆ 93.061238 ┆ 64.37548 │\n",
       "│ n         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 5        │\n",
       "│ (George)  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ High      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Presidio  ┆ 51.16     ┆ 52        ┆ 44        ┆ … ┆ 39.098491 ┆ 31.936443 ┆ 80.958686 ┆ 47.77302 │\n",
       "│ Middle    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 8        │\n",
       "│ Lafayette ┆ 23.61     ┆ 7         ┆ 96        ┆ … ┆ 0.0       ┆ 86.009098 ┆ 34.900858 ┆ 30.22748 │\n",
       "│ Elementar ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 9        │\n",
       "│ y         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Alamo Ele ┆ 14.13     ┆ 6         ┆ 74        ┆ … ┆ 0.0       ┆ 55.243183 ┆ 25.054181 ┆ 20.07434 │\n",
       "│ mentary   ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 1        │\n",
       "│ Argonne   ┆ 11.46     ┆ 4         ┆ 75        ┆ … ┆ 0.0       ┆ 56.150348 ┆ 28.927687 ┆ 21.26950 │\n",
       "│ Elementar ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 9        │\n",
       "│ y         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ Milk      ┆ 21.5      ┆ 9         ┆ 73        ┆ … ┆ 0.0       ┆ 54.352953 ┆ 52.617792 ┆ 26.74268 │\n",
       "│ (Harvey)  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 6        │\n",
       "│ Civil     ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Rights    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Ele…      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Everett   ┆ 15.2      ┆ 79        ┆ 1         ┆ … ┆ 61.228763 ┆ 0.0       ┆ 0.0       ┆ 30.61438 │\n",
       "│ Middle    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 1        │\n",
       "│ Lilientha ┆ 40.88     ┆ 31        ┆ 87        ┆ … ┆ 23.063878 ┆ 69.158131 ┆ 44.586996 ┆ 39.96822 │\n",
       "│ l         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 1        │\n",
       "│ (Claire)  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Elementar ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ y         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Marina    ┆ 35.98     ┆ 65        ┆ 17        ┆ … ┆ 48.945168 ┆ 8.509072  ┆ 35.638621 ┆ 35.50950 │\n",
       "│ Middle    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 7        │\n",
       "│ Sherman   ┆ 13.85     ┆ 15        ┆ 64        ┆ … ┆ 7.400342  ┆ 46.909982 ┆ 4.901997  ┆ 16.65316 │\n",
       "│ Elementar ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 6        │\n",
       "│ y         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrollment = polars.read_csv(workspace_path.joinpath('data/raw/rai/composite_scores_doc.csv'))\\\n",
    "    .drop(['Composite Score'])\\\n",
    "    .rename({'School Name': 'school_name'})\n",
    "\n",
    "normal_predictions = normal_predictions\\\n",
    "    .select(['school_name', 'equity_score_predicted', 'excellence_score_predicted', 'efficiency_score_predicted', 'composite_score_predicted'])\\\n",
    "    .rename({\n",
    "        'equity_score_predicted': 'equity_score_p',\n",
    "        'excellence_score_predicted': 'excellence_score_p',\n",
    "        'efficiency_score_predicted': 'efficiency_score_p',\n",
    "        'composite_score_predicted': 'composite_score_p'\n",
    "    })\n",
    "\n",
    "# merge with original\n",
    "combined_predictions = composite_df\\\n",
    "    .select(['school_name', 'composite_score', 'equity_rank', 'excellence_rank', 'efficiency_rank'])\\\n",
    "    .join(\n",
    "        enrollment,\n",
    "        on='school_name', \n",
    "        how='left'\n",
    "    )\\\n",
    "    .join(\n",
    "        normal_predictions, \n",
    "        on='school_name', \n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "combined_predictions.write_csv(workspace_path.joinpath('data/processed/component_scores.csv'))\n",
    "combined_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
